# ğŸ“ Probabilistic Machine Learning Seminar  

### ğŸ“š About  
This repository contains the code and experiments for my seminar thesis in the **Probabilistic Machine Learning** course (SoSe 2025).  
The work focuses on exploring **epistemic uncertainty** in neural networks using **partial Bayesian inference**, with a particular emphasis on:

- **Bayesian last-layer models** (Neural Linear Approximations)  
- Comparison to fully deterministic neural networks  
- Evaluation of **uncertainty calibration** and **overconfidence** on in-distribution and out-of-distribution (OOD) data

---

### ğŸ› ï¸ Core Topics
- Probabilistic modeling in neural networks  
- Bayesian linear regression as output layer  
- Predictive entropy and epistemic uncertainty  
- OOD detection via uncertainty quantification  
- Comparison to MAP-trained deterministic models

---

### ğŸ“ Project Structure

- `src/` â€“ Jupyter notebooks for experiments and visualizations  
  - `Simulation.ipynb` â€“ 1D toy regression to visualize predictive uncertainty  
  - `RealData.ipynb` â€“ Evaluation on real-world data 
  - `BayesianLLNN.py` - Implementation of Bayesian Last Layer
  - `baseNN.py` - base deterministic NN
   
- `models/` â€“ Models 
  - `baseBayes.pth` â€“ base Neural Network for Classfication
  - `basenn.pth` - Standard ReLU neural network  
  - `best_lastlayer.pth` - â€“ Neural Linear Model (Bayesian output layer)

- `Data/` â€“ Data
  - `Dataset of Diabetes.csv` - Dataset in csv format
  
- `results/` â€“ Generated plots and saved evaluation results

- `requirements.txt` â€“ Python dependencies

- `README.md` â€“ This file

---

### ğŸ“Š Datasets Used
- **Synthetic (toy) regression dataset** â€” for visualizing predictive uncertainty  
- **Real-world dataset**
  - Diabetes Diagnosis: available at [Kaggle](https://www.kaggle.com/datasets/marshalpatel3558/diabetes-prediction-dataset-legit-dataset)
  - In-distribution: known label classes  
  - OOD: unrelated or random inputs for uncertainty evaluation

---

### ğŸ“Œ Goal of the Work
To evaluate whether a simple Bayesian approximation (only in the last layer) is sufficient to capture meaningful uncertainty in predictions â€” particularly in OOD settings â€” and to compare its behavior to a fully deterministic ReLU network.

---

### LICENSE
This project is **not open-source**. All rights reserved. More infos found on [License](LICENSE) 
Unauthorized use, copying, or distribution is prohibited.



