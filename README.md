# ğŸ“ Probabilistic Machine Learning Seminar  

### ğŸ“š About  
This repository contains the code and experiments for my seminar thesis in the **Probabilistic Machine Learning** course (SoSe 2025).  
The work focuses on exploring **epistemic uncertainty** in neural networks using **partial Bayesian inference**, with a particular emphasis on:

- **Bayesian last-layer models** (Neural Linear Approximations)  
- Comparison to fully deterministic neural networks  
- Evaluation of **uncertainty calibration** and **overconfidence** on in-distribution and out-of-distribution (OOD) data

---

### ğŸ› ï¸ Core Topics
- Probabilistic modeling in neural networks  
- Bayesian linear regression as output layer  
- Predictive entropy and epistemic uncertainty  
- OOD detection via uncertainty quantification  
- Comparison to MAP-trained deterministic models

---

### ğŸ“ Project Structure

- `src/` â€“ Jupyter notebooks for experiments and visualizations  
  - `simulation_study.ipynb` â€“ 1D toy regression to visualize predictive uncertainty  
  - `real_data_experiment.ipynb` â€“ Evaluation on real-world data 

- `models/` â€“ Model definitions  
  - `deterministic_nn.py` â€“ Standard ReLU neural network  
  - `bayesian_last_layer.py` â€“ Neural Linear Model (Bayesian output layer)

- `utils/` â€“ Helper functions  
  - `uncertainty_metrics.py` â€“ Entropy, calibration error, etc.  
  - `data_loader.py` â€“ Data preprocessing and loading

- `results/` â€“ Generated plots and saved evaluation results

- `requirements.txt` â€“ Python dependencies

- `README.md` â€“ This file

---

### ğŸ“Š Datasets Used
- **Synthetic (toy) regression dataset** â€” for visualizing predictive uncertainty  
- **Real-world dataset** 
  - In-distribution: known label classes  
  - OOD: unrelated or random images for uncertainty evaluation

---

### ğŸ“Œ Goal of the Work
To evaluate whether a simple Bayesian approximation (only in the last layer) is sufficient to capture meaningful uncertainty in predictions â€” particularly in OOD settings â€” and to compare its behavior to a fully deterministic ReLU network.

---

### LICENSE

MIT LICENS


